{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CITS4403 Flavour Network Project Notebook 1\n",
    "## Flavours of the World: How Russian Cuisine Fits Within a Network of Recipes, Ingredients and Compounds from Around the Globe\n",
    "### Recipe Data\n",
    "Authors: Alden Bong (22255844), Dylan Carpenter (21982288), Luke Joshua Carpenter (22110274)\n",
    "\n",
    "Collating Russian and Eastern European Recipes from allrecipes.com, Kaggle, and (Ahn, Ahnert, Bagrow, Barabasi (2011)) Supplementary Materials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Recipes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Reading Recipe Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1. Collecting recipes from www.allrecipes.com\n",
    "\n",
    "There are 3 main steps to collect the recipe information.\n",
    "\n",
    "1. Collect the urls of pages with russian recipes\n",
    "2. Scrape the collected urls, parse the HTML and get actually recipe data\n",
    "3. Clean the data\n",
    "\n",
    "Additionally after cleaning, data can be reformatted into whatever format is desired.\n",
    "\n",
    "*Please note that this code was initially written and run in regular python scripts and then copied over into a notebook as per submission requirements*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Collecting page URLs\n",
    "\n",
    "Because AllRecipes has no publically accessible API, pages that contain recipes must be located through the website directly. As this website is dynamically populated, finding urls can be acieved though minimal manual effort and some client-side javascript run in the browser.\n",
    "\n",
    "Instructions and the required code can be found in `data/allrecipes/recipeUrls.js`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Scraping data\n",
    "\n",
    "For each recipe there are 2 tasks that need to be done: make a HTTP request to recieve the webpage and scrape the returned HTML document to extract the data we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "#pip install requests\n",
    "import requests as req\n",
    "#pip install beautifulsoup4\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#constants\n",
    "URL_FILE_PATH = \"data/allrecipes/recipe-urls.json\"\n",
    "OUPUT_FILE_PATH = \"data/allrecipes/allrecipes-recipes-russian.json\"\n",
    "CUISINE = \"Russian\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function processes a single url and returns the recipe on the page as a JSON-like object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to perform http request and parse returned HTML\n",
    "def getRecipe(url):\n",
    "    #make request\n",
    "    print(\"GET \\\"%s\\\"\" % (url), end=\"\")\n",
    "    res = req.get(url)\n",
    "    print(\"  (%d)\" % (res.status_code) )\n",
    "\n",
    "    #fail if request was not OK\n",
    "    if(res.status_code != 200):\traise Exception(\"Request was not OK\")\n",
    "\n",
    "    #create html parser\n",
    "    page = BeautifulSoup(res.text, features=\"html.parser\")\n",
    "\n",
    "    #variables we aim to populate\n",
    "    title, ingrs, ingrsBetter = \"\", [], []\n",
    "\n",
    "    #check if \"old\" style recipe title is present then extract info\n",
    "    titleTag = page.select(\"h1.headline.heading-content\")\n",
    "    if len(titleTag) == 1:\n",
    "        #page is in \"old\" layout\n",
    "        title = titleTag[0].getText().strip() #extract recipe title from h1 tag\n",
    "        #get ingredients\n",
    "        ingrTags = page.select(\".ingredients-item\") #get all ingredient item tags\n",
    "        ingrs = [tag.select(\".ingredients-item-name\")[0].getText().strip() for tag in ingrTags] #extract ingredient text\n",
    "        # in old layout ingredient entries have a standardised item field without quantity/proceedure\n",
    "        # eg. if displayed ingredient = '3 lightly beaten eggs' standard item name  = 'eggs'\n",
    "        ingrsBetter = [tag.select(\".checkbox-list-input\")[0].get(\"value\").strip() for tag in ingrTags]\n",
    "    else:\n",
    "        #page is in \"new\" layout\n",
    "        title = page.select(\"h1#recipe-main-content\")[0].getText().strip() #extract recipe title from h1 tag\n",
    "        #get ingredients\n",
    "        ingrTags = page.select(\".recipe-ingred_txt:not(.white)\") # get ingredient display tags (not .white removes \"Add All Ingredients\" listing)\n",
    "        ingrs = [tag.getText().strip() for tag in ingrTags] #extract inner text from tag\n",
    "        ingrs = list( filter(lambda x : len(x) > 0 , ingrs) ) #remove empty entries (hidden/unused HTML elements)\n",
    "        ingrsBetter = None #does not exist in new layout\n",
    "\n",
    "    #return information in dictionary format\n",
    "    return {\"name\":title, \"cuisine\":CUISINE, \"source\":url, \"ingredients\":ingrs, \"ingredientsPreprocessed\":ingrsBetter}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First load the urls from Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load urls\n",
    "urls = []\n",
    "print(\"Reading from '%s'\" % (URL_FILE_PATH))\n",
    "with open(URL_FILE_PATH) as file:\n",
    "    urls = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...then process each url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get recipes\n",
    "recipes = []\n",
    "failedUrls = []\n",
    "\n",
    "print(\"%d urls read.\\nSending requests...\" % (len(urls)) )\n",
    "for url in urls:\n",
    "    try:\n",
    "        recipes.append( getRecipe(url) )\n",
    "    except Exception as e:\n",
    "        #throws excepetion if response code is not 200 (OK)\n",
    "        failedUrls.append(url)\n",
    "\n",
    "    #sleep a bit to not look like a DOS attack (just in case)\n",
    "    time.sleep(0.25)\n",
    "\n",
    "#print failed requests (in any)\n",
    "print(\"\\nDone. (%d failed requests)\" % (len(failedUrls)))\n",
    "if len(failedUrls) > 0:\n",
    "    for url in failedUrls: print(\"\\t%s\" % (url) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finally save the recipes are JSON data for cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save json\n",
    "print(\"\\nSaving %d recipes to '%s'\\n\" % (len(recipes), OUPUT_FILE_PATH) )\n",
    "with open(OUPUT_FILE_PATH, 'w') as outfile:\n",
    "    json.dump(recipes, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Cleaning the data\n",
    "\n",
    "This was done through a small dictionary for replacing certain terms, but unfortunately was otherwise done manually to make sure the ingredients are in a friendly format.\n",
    "\n",
    "A small bit of automation was done to pick the most likely previously seen ingredient and suggest it to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants\n",
    "RECIPE_FILE_PATH = \"data/allrecipes/allrecipes-recipes-russian.json\"\n",
    "OUPUT_FILE_PATH = \"data/allrecipes/recipes-final.json\"\n",
    "\n",
    "#helper function\n",
    "def intIsParsable(str):\n",
    "    try:\n",
    "        val = int(str)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and create dictionaries and lookup sets are required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes = []\n",
    "\n",
    "with open(RECIPE_FILE_PATH, 'r') as file:\n",
    "    recipes = json.load(file)\n",
    "\n",
    "updatedRecipes = []\n",
    "ingredientSubs = {}\n",
    "\n",
    "with open(\"data/allrecipes/ingredient-substitution.json\", 'r') as file:\n",
    "    ingredientSubs = json.load(file)\n",
    "\n",
    "seenIngredients = set()\n",
    "for ingredient in ingredientSubs.values():\n",
    "    seenIngredients.add(ingredient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fairly monstrous function. Loops through ingredients in all recipes and gets user to input what the ingredient is.\n",
    "\n",
    "A dictionary of ingredients is built up over time, and suggestions for most likely ingredient as drawn from this.\n",
    "\n",
    "Process is fairly manual at the start, but as the number of seens ingredients grows, the process becomes significantly faster and more automated.\n",
    "\n",
    "**NOTE THIS CELL REQUIRES SIGNIFICANT MANUAL WORK!**\n",
    "\n",
    "**DO NOT ATTEMPT TO COMPLETE IT AND SIMPLY SKIP TO THE NEXT ONE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, recipe in enumerate(recipes):\n",
    "    print(\"%s (%d/%d):\" % (recipe[\"name\"], index+1, len(recipes)) )\n",
    "    #make new recipe for updated ingredients\n",
    "    newRecipe = {\"name\": recipe[\"name\"], \"source\": recipe[\"source\"], \"ingredients\": []}\n",
    "    #loop through ingredients (use preprocessed if they are there)\n",
    "    ingrs = recipe[\"ingredients\"] if recipe[\"ingredientsPreprocessed\"] == None else recipe[\"ingredientsPreprocessed\"]\n",
    "    for ingredient in ingrs:\n",
    "        #create suggestions for ingredients\n",
    "        candidates = []\n",
    "        if ingredient in ingredientSubs:\n",
    "            candidates.append(ingredientSubs[ingredient])\n",
    "        else:\n",
    "            candidates.extend( list(filter(lambda ingr: ingr in ingredient.lower(), seenIngredients)) )\n",
    "\n",
    "        #construct input prompt\n",
    "        prompt = \"[txt|ret|del] \"\n",
    "        for ind, candidate in enumerate(candidates):\n",
    "            prompt += \"[%d|%s] \" % (ind, candidate)\n",
    "        #get input\n",
    "        print(ingredient)\n",
    "        response = input(prompt + \": \")\n",
    "        #handle response\n",
    "        if response == \"\":\n",
    "            newRecipe[\"ingredients\"].append(ingredient.lower())\n",
    "            seenIngredients.add(ingredient.lower())\n",
    "        elif response == 'd' or response == '-':\n",
    "            pass\n",
    "        elif intIsParsable(response):\n",
    "            candidate = candidates[int(response)]\n",
    "            newRecipe[\"ingredients\"].append(candidate.lower())\n",
    "            seenIngredients.add(candidate.lower()) #technically redundant but can't hurt (much)\n",
    "        else:\n",
    "            newRecipe[\"ingredients\"].append(response.lower())\n",
    "            seenIngredients.add(response.lower())\n",
    "\n",
    "    updatedRecipes.append(newRecipe)\n",
    "    print()\n",
    "\n",
    "    #backup every 20 reicpes\n",
    "    if index % 20 == 0:\n",
    "        print(\"\\nBACKING UP\\n\\n\")\n",
    "        with open(\"backup.json\", 'w') as backup:\n",
    "            json.dump(updatedRecipes, backup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SAVE ALL THE RECIPES** - this is an important step if you just spent a few hours processing the files...\n",
    "\n",
    "*Note that for the purposes of this notebook the filepath does not point to the actual output used (as it would truncate our actual data file!)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save all recipes\n",
    "with open(OUPUT_FILE_PATH, 'w') as outfile:\n",
    "    json.dump(updatedRecipes, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done! All recipes are now cleaned and saved in a json file!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting the recipes\n",
    "\n",
    "This section of code reformats the JSON data into the CSV formats used by the flavour network [paper](https://www.nature.com/articles/srep00196 \"Flavor Network and the Principles of Food Pairing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_json(inFileName, outFileName, defaultCuisine=\"Russian\"):\n",
    "    connected_components = {}\n",
    "\n",
    "    f = open(inFileName) \n",
    "    data = json.load(f)\n",
    "\n",
    "    with open(outFileName + \"1.csv\", \"w\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "\n",
    "        for key in data:\n",
    "            try:\n",
    "                cuisine = key[\"cuisine\"]\n",
    "            except:\n",
    "                cuisine = defaultCuisine\n",
    "            ingredient_list = key['ingredients']\n",
    "\n",
    "            writer.writerow([cuisine] + ingredient_list)\n",
    "            ingredient_pairs = set(combinations(ingredient_list, 2))\n",
    "\n",
    "            # Update Ingredient Pairing Frequency\n",
    "            for pair in ingredient_pairs:\n",
    "                #print(pair)\n",
    "                if not pair in connected_components:\n",
    "                    connected_components[pair] = 1\n",
    "                else:\n",
    "                    connected_components[pair] += 1\n",
    "        f.close()\n",
    "        \n",
    "    print(connected_components)\n",
    "\n",
    "    # Write Ingredient Pairing Frequency\n",
    "    with open(outFileName + \"2.csv\", \"w\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        for key, value in connected_components.items():\n",
    "            writer.writerow([key[0], key[1], value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = \"data/\"\n",
    "WRITEPATH = \"data/supplementary_dataset/formatted_csvs/\"\n",
    "\n",
    "inFileName = DATAPATH + \"allrecipes/allrecipes-recipes-final.json\"\n",
    "outFileName = WRITEPATH + \"allrecipe_csv\"\n",
    "format_json(inFileName, outFileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2. Kaggle\n",
    "The Kaggle Dataset was retrieved from https://www.kaggle.com/kaggle/recipe-ingredients-dataset/home#train.json and is labelled \"train.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kaggle dataset is in a JSON format like the scraped allrecipes data, so we reuse the function `format_json()`\n",
    "\n",
    "*Note that this code may not run in a notebook due to a maximum data IO rate (in which case the relevant code should be run as a regular python script)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle\n",
    "inFileName = DATAPATH + \"train_dataset/train.json\"\n",
    "outFileName = WRITEPATH + \"/kaggle_csv\"\n",
    "format_json(inFileName, outFileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3. (Ahn, Ahnert, Bagrow, Barabasi (2011)) Supplementary Materials\n",
    "The Supplementary Materials Dataset was retrieved from the flavour network [paper](https://www.nature.com/articles/srep00196 \"Flavor Network and the Principles of Food Pairing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We rewrite `format_json()` to read in CSVs instead of JSONs and filter for Eastern European recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"data/supplementary_dataset/\"\n",
    "\n",
    "def format_csv(filePath):\n",
    "    from itertools import combinations\n",
    "    connected_components = {}\n",
    "\n",
    "    with open(PATH + \"formatted_csvs/supplementary_csv1.csv\", 'w') as writtenfile:\n",
    "        writer = csv.writer(writtenfile)\n",
    "        with open(filePath) as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
    "            for row in reader:\n",
    "                cuisine = row[0].split(',')[0]\n",
    "                if cuisine == 'EasternEuropean':\n",
    "                    ingredient_list = row[0].split(',')[1:]\n",
    "                    writer.writerow([cuisine] + ingredient_list)\n",
    "                    ingredient_pairs = set(combinations(ingredient_list, 2))\n",
    "\n",
    "                    # Update Ingredient Pairing Frequency\n",
    "                    for pair in ingredient_pairs:\n",
    "                        #print(pair)\n",
    "                        if not pair in connected_components:\n",
    "                            connected_components[pair] = 1\n",
    "                        else:\n",
    "                            connected_components[pair] += 1\n",
    "\n",
    "                    #print(ingredient_list)\n",
    "    # Write Ingredient Pairing Frequency\n",
    "    with open(PATH + \"formatted_csvs/supplementary_csv2.csv\", 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        for key, value in connected_components.items():\n",
    "            writer.writerow([key[0], key[1], value])\n",
    "\n",
    "filePath = 'srep00196-s3.csv'\n",
    "format_csv(PATH + filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
